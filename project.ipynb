{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 5 Project\n",
        "\n",
        "This week's project will test your understanding of this week's concepts by asking you to simulate various algorithms by hand.\n",
        "You will apply search, minimax and dynamic programming concepts to solve a variety of small planning problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeWtrixsH2uH"
      },
      "source": [
        "The full project description, a template notebook and supporting materials are available on GitHub: [Project 5 Materials](https://github.com/bu-cds-dx704/dx704-project-05)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRC-Wd81daLm"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "This week's assignment does not involve any coding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Searching vs Games\n",
        "\n",
        "Consider the state space illustrated below.\n",
        "Each terminal state state is marked with a reward for reaching that state.\n",
        "Each non-terminal state has two possible actions represented by the two outgoing arrows to later (lower) states.\n",
        "The only rewards are for reaching the terminal states, there are no diminishing returns (i.e. $\\gamma=1$), and there is no randomness so actions may be freely chosen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqIrGebXXNEA"
      },
      "source": [
        "![](https://github.com/bu-cds-dx704/dx704-project-05/blob/main/part1.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rpIFDV0rQ2-"
      },
      "source": [
        "Solve for the value of each non-terminal state according to the following three scenarios.\n",
        "\n",
        "1. Search: There is one agent that picks all actions with the goal of maximizing the final reward.\n",
        "2. Minimax: There are two agents P1 and P2. P1 controls the actions for the 1st and 3rd rows (i.e. the states marked A and D-G) while P2 controls the actions for the 2nd and 4th rows (i.e. the states B-C and H-J). P1 seeks to maximize the final reward, and P2 seeks to minimize the final reward.\n",
        "3. Maximin: P1 and P2 control the same states as before, but P1 seeks to minimize the final reward, and P2 seeks to maximize the final reward.\n",
        "\n",
        "Save your results in a file \"values-1.tsv\" with the column state with label A-J and columns search_value, minimax_value, and maximin_value that respectively correspond to the three scenarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH9SgF44sU9o"
      },
      "source": [
        "Hint: Print out the image above and compute the values by hand in a bottom up fashion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiuoS64VuPaQ"
      },
      "source": [
        "Submit the file \"values-1.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "state\tsearch_value\tminimax_value\tmaximin_value\n",
        "A\t20\t1\t0\n",
        "B\t20\t1\t9\n",
        "C\t1\t1\t0\n",
        "D\t20\t1\t9\n",
        "E\t5\t5\t3\n",
        "F\t1\t1\t-1\n",
        "G\t1\t1\t0\n",
        "H\t9\t-1\t9\n",
        "I\t20\t1\t20\n",
        "J\t3\t2\t3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to: ./values-1.tsv\n",
            "  state  search_value  minimax_value  maximin_value\n",
            "0     A            20              1              0\n",
            "1     B            20              1              9\n",
            "2     C             1              1              0\n",
            "3     D            20              1              9\n",
            "4     E             5              5              3\n",
            "5     F             1              1             -1\n",
            "6     G             1              1              0\n",
            "7     H             9             -1              9\n",
            "8     I            20              1             20\n",
            "9     J             3              2              3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ---- values for Part 1 ----\n",
        "data = [\n",
        "    (\"A\", 20, 1, 0),\n",
        "    (\"B\", 20, 1, 9),\n",
        "    (\"C\",  1, 1, 0),   # minimax(C) = min(1,1) = 1\n",
        "    (\"D\", 20, 1, 9),\n",
        "    (\"E\",  5, 5, 3),\n",
        "    (\"F\",  1, 1, -1),\n",
        "    (\"G\",  1, 1, 0),\n",
        "    (\"H\",  9, -1, 9),\n",
        "    (\"I\", 20, 1, 20),\n",
        "    (\"J\",  3, 2, 3),\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(data, columns=[\"state\",\"search_value\",\"minimax_value\",\"maximin_value\"])\n",
        "\n",
        "# pick a write location that exists\n",
        "out_dir = \"/mnt/data\" if os.path.isdir(\"/mnt/data\") else \".\"\n",
        "out_path = os.path.join(out_dir, \"values-1.tsv\")\n",
        "\n",
        "df.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "print(f\"Saved to: {out_path}\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfvETFzfbLtM"
      },
      "source": [
        "## Part 2: Picking Up Sticks\n",
        "\n",
        "The state space illustrated below corresponds to a variation of the game [Nim](https://en.wikipedia.org/wiki/Nim).\n",
        "States labeled with a prefix of \"p1_\" correspond to states where player P1 chooses the action while states labeled with a prefix of \"p2_\" correspond to states where player P2 chooses the action.\n",
        "The number in the suffix is the number of \"sticks\" remaining.\n",
        "The players take turns choosing actions, and each action corresponds to removing one or two sticks.\n",
        "When there are no more sticks, the player who would have picked an action loses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvbiyLjebPz4"
      },
      "source": [
        "![](https://github.com/bu-cds-dx704/dx704-project-05/blob/main/part2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iwgAVJptral"
      },
      "source": [
        "For example, from the state labeled \"p1_1\", there is one stick left, player P1 removes the last stick, and player P2 loses.\n",
        "The loss for P2 is represented by a final reward of +1.\n",
        "A loss for P1 is represented by a final reward of -1.\n",
        "Player P1 tries to maximize the final reward, and player P2 tries to minimize the final reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cHZf7Y7t0rN"
      },
      "source": [
        "Solve for the value of each of the non-terminal states.\n",
        "Save the results in a file \"values-2.tsv\" with columns state and value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p1_1\t1\n",
            "p1_2\t1\n",
            "p1_3\t-1\n",
            "p1_4\t1\n",
            "p1_5\t1\n",
            "p2_1\t-1\n",
            "p2_2\t-1\n",
            "p2_3\t1\n",
            "p2_4\t-1\n",
            "p2_5\t-1\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from functools import lru_cache\n",
        "MAX=5\n",
        "@lru_cache(None)\n",
        "def V(p,n):\n",
        "    if n==0: return -1 if p==1 else 1\n",
        "    ns=[n-1]+([n-2] if n>1 else [])\n",
        "    return (max if p==1 else min)(V(3-p,m) for m in ns)\n",
        "rows=[(f\"p1_{n}\",V(1,n)) for n in range(1,MAX+1)]+[(f\"p2_{n}\",V(2,n)) for n in range(1,MAX+1)]\n",
        "with open(\"values-2.tsv\",\"w\",newline=\"\") as f:\n",
        "    csv.writer(f,delimiter=\"\\t\").writerows([[\"state\",\"value\"],*rows])\n",
        "print(\"\\n\".join(f\"{s}\\t{v}\" for s,v in rows))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote values-2.tsv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache(None)\n",
        "def V(player, n):\n",
        "    if n == 0:  # player to move loses\n",
        "        return -1 if player == 1 else 1\n",
        "    nxt = (n-1, n-2) if n > 1 else (n-1,)\n",
        "    choose = max if player == 1 else min\n",
        "    return choose(V(3 - player, m) for m in nxt)\n",
        "\n",
        "rows = [(\"state\",\"value\")]\n",
        "rows += [(f\"p1_{n}\", V(1, n)) for n in range(1, 6)]\n",
        "rows += [(f\"p2_{n}\", V(2, n)) for n in range(1, 6)]\n",
        "\n",
        "with open(\"values-2.tsv\", \"w\", newline=\"\") as f:\n",
        "    csv.writer(f, delimiter=\"\\t\").writerows(rows)\n",
        "\n",
        "print(\"Wrote values-2.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLkvKANCuTkK"
      },
      "source": [
        "Submit the file \"values-2.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWFScR_kuVnU"
      },
      "source": [
        "## Part 3: Searching a Maze\n",
        "\n",
        "Consider the following maze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqPKQ9mEx7Al"
      },
      "source": [
        "![](https://github.com/bu-cds-dx704/dx704-project-05/blob/main/part3.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NtP8sDMvTSS"
      },
      "source": [
        "State C is a terminal state giving reward +100.\n",
        "The remaining states have a reward of -1 when they are reached.\n",
        "So moving to state F has a value of +99 do to the reward of -1 at state F and the optimal action of moving to state C for the reward of +100 afterwards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82BHKa1syjEk"
      },
      "source": [
        "Compute the values for states A-J and S and save them in a file \"values-3.tsv\" with columns state and value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "state\tvalue\n",
        "A\t    92\n",
        "B\t    94\n",
        "C\t   100\n",
        "D\t    95\n",
        "E\t    95\n",
        "F\t    99\n",
        "G\t    96\n",
        "H\t    96\n",
        "I\t    97\n",
        "J\t    98\n",
        "S\t    93\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote values-3.tsv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "from collections import deque\n",
        "\n",
        "# Directed edges from the figure\n",
        "edges = {\n",
        "    \"A\": [\"S\"],\n",
        "    \"B\": [\"D\", \"S\"],\n",
        "    \"C\": [],                 # terminal (+100)\n",
        "    \"D\": [\"B\", \"E\", \"G\"],\n",
        "    \"E\": [\"D\", \"H\"],\n",
        "    \"F\": [\"C\", \"J\"],\n",
        "    \"G\": [\"D\", \"I\"],\n",
        "    \"H\": [\"E\", \"I\"],\n",
        "    \"I\": [\"G\", \"H\", \"J\"],\n",
        "    \"J\": [\"F\", \"I\"],\n",
        "    \"S\": [\"A\", \"B\"],\n",
        "}\n",
        "\n",
        "# Build reverse graph and BFS from C to get shortest steps TO C\n",
        "rev = {n: [] for n in edges}\n",
        "for u, nbrs in edges.items():\n",
        "    for v in nbrs:\n",
        "        rev[v].append(u)\n",
        "\n",
        "dist = {n: float(\"inf\") for n in edges}\n",
        "q = deque([\"C\"])\n",
        "dist[\"C\"] = 0\n",
        "while q:\n",
        "    v = q.popleft()\n",
        "    for u in rev[v]:\n",
        "        if dist[u] > dist[v] + 1:\n",
        "            dist[u] = dist[v] + 1\n",
        "            q.append(u)\n",
        "\n",
        "# Value = 100 - distance-to-C\n",
        "order = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"S\"]\n",
        "rows = [(\"state\",\"value\")] + [(n, int(100 - dist[n])) for n in order]\n",
        "\n",
        "with open(\"values-3.tsv\", \"w\", newline=\"\") as f:\n",
        "    csv.writer(f, delimiter=\"\\t\").writerows(rows)\n",
        "\n",
        "print(\"Wrote values-3.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAKgdr4XysuK"
      },
      "source": [
        "Submit \"values-3.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 4: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "none"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
